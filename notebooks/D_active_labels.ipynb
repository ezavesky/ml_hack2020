{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Machine Learning Workshop: Content Insights 2020](assets/mlci_banner.jpg)\n",
    "\n",
    "# Machine Learning Workshop: Content Insights 2020\n",
    "\n",
    "Welcome to the workshop notebooks!  These notebooks are designed to give you a walk through the steps of creating a model, refining it with user labels, and testing it on content.  You can access the main [workshop forum page](https://INFO_SITE/forums/html/forum?id=241a0b77-7aa6-4fef-9f25-5ea351825725&ps=25), the [workshop files repo](https://INFO_SITE/communities/service/html/communityview?communityUuid=fb400868-b17c-44d8-8b63-b445d26a0be4#fullpageWidgetId=W403a0d6f86de_45aa_8b67_c52cf90fca16&folder=d8138bef-9182-4bdc-8b12-3c88158a219c), or the [symposium home page](https://software.web.DOMAIN) for additional help.\n",
    "\n",
    "The notebooks are divided into five core components: (A) setup & data, (B) model exploration, (C) labeling, (D) active labeling, (E) and deployment.  You are currently viewing the *setup & data* workbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants for running the workshop; we'll repeat these in the top line of each workbook.\n",
    "#   why repeat them? the backup routine only serializes .ipynb files, so others will need \n",
    "#   to be downloaded again if your compute instance restarts (a small price to pay, right?)\n",
    "\n",
    "AGG_AVFEAT = \"agg_avfeature.pkl.gz\"             # custom file for merged audio and video features\n",
    "CLASS_LABELS_FLAT = \"assets/labels_final.json\"  # provided file for label info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook D: Active Labeling Analysis\n",
    "\n",
    "Now that we've reviewed **how** you can solicit labels and update the order of that solicitation, let's anlayze the implications of solicitation reording.  The late notebook focused on interacting with the labeling interface, so here we'll just use offline labels and simulate labeler entries.  Additionally, this notebook will focus on the training of a custom classifier instead of reusing other tags.\n",
    "\n",
    "In this notebook, we evaluate a few critical questions.\n",
    "\n",
    "1. Does reranking unlabeled instance (e.g. online learning) help to improve efficiency?\n",
    "1. What strategies for ordering results can improve labeling efficiency?\n",
    "1. What consensus measures should be taken for multiple labels?\n",
    "1. Are there trends in performance curves that can point to a moment of model stability?\n",
    "\n",
    "If you're really curious about the space, this overview paper, [A Wholistic View of Continual Learning with Deep Neural Networks: â€¨",
    "Forgotten Lessons and the Bridge to Active and Open World Learning](https://arxiv.org/abs/2009.01797), gives a great (and dizzying) review of active learning topics.\n",
    "\n",
    "![Machine Learning Workshop: Content Insights 2020](assets/active_overview.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Basics\n",
    "The cell below provides our basic training functions that are utilized in the notebook.  It is derived from the av-featuretraing method (classifier 3) evaluated in notebook B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a total of 1229 labels across 779 samples and 6 classes.\n",
      "Loaded a total of 1033 samples.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# define scorng functions\n",
    "def classifier_score(df_prediction, df_labels, class_name):\n",
    "    \"\"\"Functiont to provide metric outputs for the evaluation of a prediction dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "        df_prediction (DataFrame): dataframe containing 'asset' and 'score' as columns\n",
    "        df_labels (DataFrame): dataframe containing 'asset' and 'label' for labels\n",
    "        class_name (str): class name for evaluation against labels\n",
    "\n",
    "    Returns:\n",
    "        dict of metrics (AUC, AP, precision, recall) ({\"ap\":X, \"class\":Y, ...}) and joined dataframe\n",
    "    \"\"\"\n",
    "    metrics_obj = {\"class\":class_name}\n",
    "    \n",
    "    # clean up input labels, prune to relevant class\n",
    "    df_labels = df_labels[df_labels[\"class\"] == class_name].drop(columns=[\"etag\", \"url\"]) \n",
    "    # join labels and scores by asset, nomalize score to float\n",
    "    df_join = df_prediction.set_index('asset').join(df_labels.set_index('asset'), how=\"left\").fillna(0)  # joint at asset level, 0 for nonscoring\n",
    "    df_join[\"class\"] = df_join[\"class\"].apply(lambda x: 1 if x != 0 else 0).astype(int)\n",
    "    df_join = df_join.reset_index().sort_values(\"score\", ascending=False)\n",
    "\n",
    "    # print(f\"{class_name}: Found {len(df_join)} samples from {len(df_labels)} labels and {len(df_prediction)} scores.\")\n",
    "\n",
    "    def thresh(x):\n",
    "        return 1 if x >= 0.5 else 0\n",
    "    \n",
    "    metrics_obj[\"AP\"] = metrics.average_precision_score(df_join['class'], df_join['score'])\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(df_join['class'], df_join['score'])\n",
    "    metrics_obj[\"AUC\"] = metrics.auc(fpr, tpr)\n",
    "    metrics_obj[\"Accuracy\"] = metrics.accuracy_score(df_join['class'], df_join['score'].apply(thresh))\n",
    "    metrics_obj[\"Recall\"] = metrics.recall_score(df_join['class'], df_join['score'].apply(thresh))\n",
    "    metrics_obj[\"F1\"] = metrics.f1_score(df_join['class'], df_join['score'].apply(thresh))\n",
    "    # print(f\"{class_name}: {metrics_obj}\")\n",
    "        \n",
    "    # return our computation!\n",
    "    return metrics_obj, df_join\n",
    "\n",
    "def classifier_plot(metrics_obj, df_scored):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(df_scored['class'], df_scored['score'])\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(11, 4))\n",
    "\n",
    "    lw = 2\n",
    "    ax1.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label=f\"AUC curve (area={metrics_obj['AUC']:0.2})\")\n",
    "    ax1.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    ax1.set_xlim([0.0, 1.0])\n",
    "    ax1.set_ylim([0.0, 1.05])\n",
    "    ax1.set_xlabel('False Positive Rate')\n",
    "    ax1.set_ylabel('True Positive Rate')\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(df_scored['class'], df_scored['score'])\n",
    "    ax2.plot(recall, precision, color='red',\n",
    "             lw=lw, label=f\"PR Curve (AP={metrics_obj['AP']:0.2}, F1={metrics_obj['F1']:0.2})\")\n",
    "    ax2.plot([1, 0], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    ax2.set_xlim([0.0, 1.0])\n",
    "    ax2.set_ylim([0.0, 1.05])\n",
    "    ax2.set_ylabel('Precision')\n",
    "    ax2.set_xlabel('Recall')\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "    \n",
    "# read label data for use later!\n",
    "df_labels = pd.read_json(CLASS_LABELS_FLAT).explode('labels').fillna('none of the above')\n",
    "df_labels.rename(columns={\"data\":\"url\", \"labels\":\"class\"}, inplace=True)\n",
    "df_labels[\"asset\"] = df_labels['url'].replace(regex={r'^' + WORKSHOP_BASE + '/': ''})\n",
    "print(f\"Loaded a total of {len(df_labels)} labels across {len(df_labels['asset'].unique())} samples and {len(df_labels['class'].unique())} classes.\")\n",
    "\n",
    "# clear out other performance stores\n",
    "df_performance = None\n",
    "\n",
    "# load features\n",
    "path_features = Path(AGG_AVFEAT)\n",
    "if not path_features.exists():\n",
    "    raise Exception(f\"\"\"\n",
    "       Sorry, the set of aggregate features was not found.  \n",
    "       Please return to notebook B to create file '{str(path_features)}'...\n",
    "    \"\"\")\n",
    "df_avfeature = pd.read_pickle(str(path_features))\n",
    "print(f\"Loaded a total of {len(df_avfeature)} samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>etag</th>\n",
       "      <th>class</th>\n",
       "      <th>url</th>\n",
       "      <th>asset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a039cb37f290fe4a4127bbd2</td>\n",
       "      <td>holiday</td>\n",
       "      <td>https://vmlr-workshop.STORAGE/gifts/v...</td>\n",
       "      <td>gifts/vid_gift_give_take_8-4-of-12.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a039cb37f290fe4a4127bbd2</td>\n",
       "      <td>gift giving</td>\n",
       "      <td>https://vmlr-workshop.STORAGE/gifts/v...</td>\n",
       "      <td>gifts/vid_gift_give_take_8-4-of-12.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a039cb37f290fe4a4127bbd2</td>\n",
       "      <td>family moments</td>\n",
       "      <td>https://vmlr-workshop.STORAGE/gifts/v...</td>\n",
       "      <td>gifts/vid_gift_give_take_8-4-of-12.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b6dbe02fdf00f08a61a44b8f</td>\n",
       "      <td>holiday</td>\n",
       "      <td>https://vmlr-workshop.STORAGE/gifts/v...</td>\n",
       "      <td>gifts/vid_gift_give_take_28-7-of-16.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b6dbe02fdf00f08a61a44b8f</td>\n",
       "      <td>gift giving</td>\n",
       "      <td>https://vmlr-workshop.STORAGE/gifts/v...</td>\n",
       "      <td>gifts/vid_gift_give_take_28-7-of-16.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>8355de7a556d5068a4e0bb67</td>\n",
       "      <td>family moments</td>\n",
       "      <td>https://vmlr-workshop.STORAGE/xmas/vi...</td>\n",
       "      <td>xmas/vid_xmas_3-40-of-79.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>628fe25f2e8c656689d70026</td>\n",
       "      <td>family moments</td>\n",
       "      <td>https://vmlr-workshop.STORAGE/gifts/v...</td>\n",
       "      <td>gifts/vid_gift_give_take_43-2-of-4.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>28a0b165ed9b04d82dd2139c</td>\n",
       "      <td>holiday</td>\n",
       "      <td>https://vmlr-workshop.STORAGE/xmas/vi...</td>\n",
       "      <td>xmas/vid_xmas_9-23-of-67.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>28a0b165ed9b04d82dd2139c</td>\n",
       "      <td>shopping scenes</td>\n",
       "      <td>https://vmlr-workshop.STORAGE/xmas/vi...</td>\n",
       "      <td>xmas/vid_xmas_9-23-of-67.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>afb82ab94ac47d9dc06de9db</td>\n",
       "      <td>halloween</td>\n",
       "      <td>https://vmlr-workshop.STORAGE/hallowe...</td>\n",
       "      <td>halloween/vid_halloween_6-31-of-34.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1229 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         etag            class  \\\n",
       "0    a039cb37f290fe4a4127bbd2          holiday   \n",
       "0    a039cb37f290fe4a4127bbd2      gift giving   \n",
       "0    a039cb37f290fe4a4127bbd2   family moments   \n",
       "1    b6dbe02fdf00f08a61a44b8f          holiday   \n",
       "1    b6dbe02fdf00f08a61a44b8f      gift giving   \n",
       "..                        ...              ...   \n",
       "775  8355de7a556d5068a4e0bb67   family moments   \n",
       "776  628fe25f2e8c656689d70026   family moments   \n",
       "777  28a0b165ed9b04d82dd2139c          holiday   \n",
       "777  28a0b165ed9b04d82dd2139c  shopping scenes   \n",
       "778  afb82ab94ac47d9dc06de9db        halloween   \n",
       "\n",
       "                                                   url  \\\n",
       "0    https://vmlr-workshop.STORAGE/gifts/v...   \n",
       "0    https://vmlr-workshop.STORAGE/gifts/v...   \n",
       "0    https://vmlr-workshop.STORAGE/gifts/v...   \n",
       "1    https://vmlr-workshop.STORAGE/gifts/v...   \n",
       "1    https://vmlr-workshop.STORAGE/gifts/v...   \n",
       "..                                                 ...   \n",
       "775  https://vmlr-workshop.STORAGE/xmas/vi...   \n",
       "776  https://vmlr-workshop.STORAGE/gifts/v...   \n",
       "777  https://vmlr-workshop.STORAGE/xmas/vi...   \n",
       "777  https://vmlr-workshop.STORAGE/xmas/vi...   \n",
       "778  https://vmlr-workshop.STORAGE/hallowe...   \n",
       "\n",
       "                                       asset  \n",
       "0     gifts/vid_gift_give_take_8-4-of-12.mp4  \n",
       "0     gifts/vid_gift_give_take_8-4-of-12.mp4  \n",
       "0     gifts/vid_gift_give_take_8-4-of-12.mp4  \n",
       "1    gifts/vid_gift_give_take_28-7-of-16.mp4  \n",
       "1    gifts/vid_gift_give_take_28-7-of-16.mp4  \n",
       "..                                       ...  \n",
       "775             xmas/vid_xmas_3-40-of-79.mp4  \n",
       "776   gifts/vid_gift_give_take_43-2-of-4.mp4  \n",
       "777             xmas/vid_xmas_9-23-of-67.mp4  \n",
       "777             xmas/vid_xmas_9-23-of-67.mp4  \n",
       "778   halloween/vid_halloween_6-31-of-34.mp4  \n",
       "\n",
       "[1229 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "def classify_av():\n",
    "    cv_folds = 5\n",
    "    feature = \"combined\"\n",
    "    score_calibrate = False\n",
    "    cv_jobs = -1  # -1 is auto, otherwise specific number\n",
    "    dict_results = {}\n",
    "    for idx in range(len(df_classes)):  # iterate classes for evaluation\n",
    "        row = df_classes.iloc[idx]\n",
    "        tag_match = []\n",
    "\n",
    "        df_label_sub = df_labels[df_labels[\"class\"]==row[\"class\"]]  # subselect for this class\n",
    "        df_feat = df_avfeature.set_index(\"asset\").copy()   # get slice of right features\n",
    "        df_feat = df_feat.join(df_label_sub.set_index(\"asset\"), how=\"left\").fillna(0)  # join with labels\n",
    "        df_feat[\"class\"] = df_feat[\"class\"].apply(lambda x: 1 if x != 0 else 0).astype(int)  # blank out text\n",
    "        \n",
    "        model = LogisticRegression()  # basic logistic regression\n",
    "        if score_calibrate:   # try to re-calibrate outputs for better threshold?\n",
    "            model = CalibratedClassifierCV(model, method=\"sigmoid\")\n",
    "        probs = cross_val_predict(model, np.vstack(df_feat[feature]), \n",
    "                                  df_feat[\"class\"], cv=cv_folds, \n",
    "                                  n_jobs=cv_jobs, method='predict_proba')\n",
    "        df_feat[\"score\"] = probs[:,1]  # grab prediction for second class\n",
    "        df_feat = df_feat.reset_index().drop(columns=['class'])  # reset index, drop label\n",
    "\n",
    "        metrics_obj, df_scored = classifier_score(df_feat[[\"asset\", \"score\"]], df_labels, row['class'])\n",
    "        dict_results[row['class']] = {'class':row['class'], 'method':f'avfeat', \n",
    "                                      'token':['audio', 'video'] if feature==\"combined\" else [feature], \n",
    "                                      \"details\":f\"{feature}_{score_calibrate}\",\n",
    "                                      'metrics': metrics_obj, 'scored': df_scored}\n",
    "    return dict_results\n",
    "\n",
    "def result_retrain(run_name, modality, calibrate):\n",
    "    global df_performance\n",
    "    details_mode = f\"{modality}_{calibrate}\"\n",
    "    if len(df_performance[df_performance[\"details\"]==details_mode]) == 0:\n",
    "        print(\"Model condition change detected, retraining classifier...\")\n",
    "        dict_results = classify_av(modality, calibrate)\n",
    "        df_performance = result_update(df_performance, dict_results)   # save results\n",
    "\n",
    "# first time run\n",
    "dict_results = classify_av()\n",
    "df_performance = result_update(df_performance, dict_results)   # save results\n",
    "\n",
    "# use widget interaction basic\n",
    "dropdown = widgets.interactive(result_retrain\n",
    "    ,run_name=widgets.Dropdown(\n",
    "        options=list(df_performance[df_performance['method']==\"avfeat\"].index),  # send run names\n",
    "        value=list(df_performance[df_performance['method']==\"avfeat\"].index)[0],  # send run names\n",
    "        description='Class Name:',\n",
    "        disabled=False)\n",
    "    ,modality=widgets.Dropdown(options=['combined', 'audio', 'video'], description='Modality:')\n",
    "    ,calibrate=widgets.Checkbox(value=False, description='Score re-calibration')\n",
    ")\n",
    "output = dropdown.children[-1]  # anti-flicker trick (https://ipywidgets.readthedocs.io/en/stable/examples/Using%20Interact.html#Flickering-and-jumping-output)\n",
    "# output.layout.height = '750px'  # disable this if you make your output window longer!\n",
    "display(dropdown)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reranking to Improve Efficency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reranking Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consensus Measures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Active Learning Material\n",
    "\n",
    "This is where the core technical evaluations end, congratulations -- you made it!  Armed with this knowledge, you have a few strategies to map from a new concept into a custom av-centric classifier with several evaluation metrics along the way.  \n",
    "\n",
    "The next notebook, [notebook E](E_deployment.ipynb) *(that link may not work)* visits advanced methods that can apply and utilize models generated from these work books.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
